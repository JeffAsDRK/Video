{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4351af78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.100.178:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Loading /home/orangepi/yolo11n_rknn_model for RKNN inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W Query dynamic range failed. Ret code: RKNN_ERR_MODEL_INVALID. (If it is a static shape RKNN model, please ignore the above warning message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I RKNN: [05:55:08.560] RKNN Runtime Information, librknnrt version: 1.6.0 (9a7b5d24c@2023-12-13T17:31:11)\n",
      "I RKNN: [05:55:08.561] RKNN Driver Information, version: 0.9.6\n",
      "I RKNN: [05:55:08.561] RKNN Model Information, version: 6, toolkit version: 2.3.2(compiler version: 2.3.2 (e045de294f@2025-04-07T19:48:25)), target: RKNPU v2, target platform: rk3588, framework name: ONNX, framework layout: NCHW, model inference type: static_shape\n",
      "W RKNN: [05:55:08.561] RKNN Model version: 2.3.2 not match with rknn runtime version: 1.6.0\n",
      "W RKNN: [05:55:08.590] query RKNN_QUERY_INPUT_DYNAMIC_RANGE error, rknn model is static shape type, please export rknn with dynamic_shapes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.100.229 - - [18/Jul/2025 05:55:23] \"GET /?infer=cam3 HTTP/1.1\" 200 -\n",
      "192.168.100.229 - - [18/Jul/2025 05:55:23] \"GET /yolo_feed/cam3 HTTP/1.1\" 200 -\n",
      "192.168.100.229 - - [18/Jul/2025 05:55:23] \"GET /video_feed/cam1 HTTP/1.1\" 200 -\n",
      "192.168.100.229 - - [18/Jul/2025 05:55:23] \"GET /video_feed/cam4 HTTP/1.1\" 200 -\n",
      "192.168.100.229 - - [18/Jul/2025 05:55:23] \"GET /video_feed/cam2 HTTP/1.1\" 200 -\n",
      "192.168.100.229 - - [18/Jul/2025 05:55:23] \"GET /video_feed/cam3 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-12:\n",
      "Process Process-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-9:\n",
      "  File \"/tmp/ipykernel_1841769/3371036987.py\", line 71, in yolo_inference_process\n",
      "    output_dict[cam_id] = annotated\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-8:\n",
      "Process Process-10:\n",
      "  File \"<string>\", line 2, in __setitem__\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1841769/3371036987.py\", line 48, in reader_process\n",
      "    buffer.append((timestamp, frame))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/managers.py\", line 817, in _callmethod\n",
      "    conn.send((self._id, methodname, args, kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"<string>\", line 2, in append\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1841769/3371036987.py\", line 48, in reader_process\n",
      "    buffer.append((timestamp, frame))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 405, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/tmp/ipykernel_1841769/3371036987.py\", line 40, in reader_process\n",
      "    raw_frame = process.stdout.read(width * height * 3)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/managers.py\", line 817, in _callmethod\n",
      "    conn.send((self._id, methodname, args, kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"<string>\", line 2, in append\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 405, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/managers.py\", line 817, in _callmethod\n",
      "    conn.send((self._id, methodname, args, kwds))\n",
      "  File \"/tmp/ipykernel_1841769/3371036987.py\", line 46, in reader_process\n",
      "    while buffer and timestamp - buffer[0][0] > buffer_seconds:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"<string>\", line 2, in __len__\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 405, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/managers.py\", line 818, in _callmethod\n",
      "    kind, result = conn.recv()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, Response, render_template_string, request\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import cv2\n",
    "from multiprocessing import Process, Manager\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Cámaras disponibles\n",
    "cameras = {\n",
    "    \"cam1\": \"rtsp://admin:asd12345@192.168.0.249/Streaming/Channels/102/\",\n",
    "    \"cam2\": \"rtsp://admin:asd12345@192.168.0.249/Streaming/Channels/202/\",\n",
    "    \"cam3\": \"rtsp://admin:asd12345@192.168.0.249/Streaming/Channels/302/\",\n",
    "    \"cam4\": \"rtsp://admin:asd12345@192.168.0.249/Streaming/Channels/402/\",\n",
    "}\n",
    "\n",
    "width, height = 960, 576\n",
    "buffer_seconds = 1\n",
    "manager = Manager()\n",
    "camera_buffers = manager.dict()\n",
    "yolo_output = manager.dict()  # Aquí se guarda el último frame con inferencia\n",
    "\n",
    "def create_ffmpeg_process(rtsp_url):\n",
    "    return subprocess.Popen([\n",
    "        \"ffmpeg\", \"-rtsp_transport\", \"tcp\", \"-i\", rtsp_url,\n",
    "        \"-f\", \"rawvideo\", \"-pix_fmt\", \"bgr24\",\n",
    "        \"-vf\", f\"scale={width}:{height}\",\n",
    "        \"-loglevel\", \"quiet\", \"-\"\n",
    "    ], stdout=subprocess.PIPE, bufsize=2**8)\n",
    "\n",
    "def reader_process(cam_id, rtsp_url, shared_dict):\n",
    "    buffer = manager.list()\n",
    "    shared_dict[cam_id] = buffer\n",
    "    process = create_ffmpeg_process(rtsp_url)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            raw_frame = process.stdout.read(width * height * 3)\n",
    "            if len(raw_frame) != width * height * 3:\n",
    "                continue\n",
    "            frame = np.frombuffer(raw_frame, np.uint8).reshape((height, width, 3))\n",
    "            timestamp = time.time()\n",
    "\n",
    "            while buffer and timestamp - buffer[0][0] > buffer_seconds:\n",
    "                buffer.pop(0)\n",
    "            buffer.append((timestamp, frame))\n",
    "    finally:\n",
    "        process.terminate()\n",
    "\n",
    "def yolo_inference_process(cam_id, shared_buffers, output_dict):\n",
    "    model = YOLO(\"/home/orangepi/yolo11n_rknn_model\")  # Puedes usar otro modelo aquí\n",
    "\n",
    "    while True:\n",
    "        if cam_id not in shared_buffers:\n",
    "        \n",
    "            continue\n",
    "\n",
    "        buffer = shared_buffers[cam_id]\n",
    "        if len(buffer) < 2:\n",
    "            \n",
    "            continue\n",
    "\n",
    "        mid_index = len(buffer) // 3\n",
    "        selected_frames = [frame for _, frame in list(buffer)[mid_index:]]\n",
    "\n",
    "        for frame in selected_frames:\n",
    "            results = model(frame,verbose=False)\n",
    "            annotated = results[0].plot()\n",
    "            output_dict[cam_id] = annotated\n",
    "\n",
    "@app.route('/video_feed/<cam_id>')\n",
    "def video_feed(cam_id):\n",
    "    if cam_id not in camera_buffers:\n",
    "        return \"Cámara no encontrada\", 404\n",
    "\n",
    "    def generate():\n",
    "        last_time = 0\n",
    "        while True:\n",
    "            buffer = camera_buffers[cam_id]\n",
    "            if not buffer:\n",
    "                continue\n",
    "\n",
    "            for i, (ts, frame) in enumerate(buffer):\n",
    "                if ts > last_time:\n",
    "                    last_time = ts\n",
    "                    ret, jpeg = cv2.imencode('.jpg', frame)\n",
    "                    if not ret:\n",
    "                        continue\n",
    "                    yield (b'--frame\\r\\n'\n",
    "                           b'Content-Type: image/jpeg\\r\\n\\r\\n' + jpeg.tobytes() + b'\\r\\n')\n",
    "                    break\n",
    "\n",
    "    return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/yolo_feed/<cam_id>')\n",
    "def yolo_feed(cam_id):\n",
    "    if cam_id not in yolo_output:\n",
    "        return \"Inferencia no disponible aún\", 404\n",
    "\n",
    "    def generate():\n",
    "        while True:\n",
    "            if cam_id in yolo_output:\n",
    "                frame = yolo_output[cam_id]\n",
    "                ret, jpeg = cv2.imencode('.jpg', frame)\n",
    "                if ret:\n",
    "                    yield (b'--frame\\r\\n'\n",
    "                           b'Content-Type: image/jpeg\\r\\n\\r\\n' + jpeg.tobytes() + b'\\r\\n')\n",
    "\n",
    "    return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    selected_cam = request.args.get(\"infer\", \"\")\n",
    "    html = \"\"\"\n",
    "    <html>\n",
    "    <head><title>Multi-Cámara + YOLO</title></head>\n",
    "    <body>\n",
    "      <h1>Cámaras en Vivo</h1>\n",
    "      {% for cam_id in cameras %}\n",
    "        <div>\n",
    "          <h2>{{ cam_id }}</h2>\n",
    "          <img src=\"/video_feed/{{ cam_id }}\" width=\"640\" height=\"360\" />\n",
    "        </div>\n",
    "      {% endfor %}\n",
    "      <h1>Inferencia YOLO</h1>\n",
    "      {% if selected_cam %}\n",
    "        <p>Inferencia activa en: <strong>{{ selected_cam }}</strong></p>\n",
    "        <img src=\"/yolo_feed/{{ selected_cam }}\" width=\"640\" height=\"360\" />\n",
    "      {% else %}\n",
    "        <p>No se ha seleccionado cámara para inferencia.</p>\n",
    "      {% endif %}\n",
    "      <form method=\"get\">\n",
    "        <label for=\"infer\">Selecciona cámara para inferencia:</label>\n",
    "        <select name=\"infer\">\n",
    "          {% for cam_id in cameras %}\n",
    "            <option value=\"{{ cam_id }}\">{{ cam_id }}</option>\n",
    "          {% endfor %}\n",
    "        </select>\n",
    "        <input type=\"submit\" value=\"Activar YOLO\">\n",
    "      </form>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return render_template_string(html, cameras=cameras.keys(), selected_cam=selected_cam)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Procesos de lectura\n",
    "    processes = []\n",
    "    for cam_id, rtsp_url in cameras.items():\n",
    "        p = Process(target=reader_process, args=(cam_id, rtsp_url, camera_buffers), daemon=True)\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    # Cámara seleccionada para inferencia (puedes cambiar esto dinámicamente)\n",
    "    selected_camera = \"cam3\"\n",
    "    p_infer = Process(target=yolo_inference_process, args=(selected_camera, camera_buffers, yolo_output), daemon=True)\n",
    "    p_infer.start()\n",
    "    processes.append(p_infer)\n",
    "\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46efe58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, Response, render_template_string\n",
    "import cv2\n",
    "from threading import Thread\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "camera_urls = {\n",
    "    \"cam1\": \"rtsp://admin:asd12345@192.168.0.249/Streaming/Channels/102/\",\n",
    "    \"cam2\": \"rtsp://admin:asd12345@192.168.0.249/Streaming/Channels/202/\",\n",
    "    \"cam3\": \"rtsp://admin:asd12345@192.168.0.249/Streaming/Channels/302/\",\n",
    "    \"cam4\": \"rtsp://admin:asd12345@192.168.0.249/Streaming/Channels/402/\",\n",
    "    \"cam5\": \"rtsp://admin:asd12345@192.168.0.249/Streaming/Channels/502/\",\n",
    "    \"cam6\": \"rtsp://admin:asd12345@192.168.0.249/Streaming/Channels/702/\",\n",
    "}\n",
    "\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "latest_frames = {cam_id: None for cam_id in camera_urls}\n",
    "last_detected_frames = {cam_id: None for cam_id in camera_urls}  # Guardamos frames con detección\n",
    "frame_counters = {cam_id: 0 for cam_id in camera_urls}\n",
    "infer_interval = 2\n",
    "\n",
    "def camera_reader(cam_id, url):\n",
    "    cap = cv2.VideoCapture(url)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[{cam_id}] No se pudo abrir el stream.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"[{cam_id}] Error al leer frame.\")\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "        frame_counters[cam_id] += 1\n",
    "\n",
    "        if frame_counters[cam_id] % infer_interval == 0:\n",
    "            results = model(frame, verbose=False,device=0)\n",
    "            frame_with_boxes = results[0].plot()\n",
    "            last_detected_frames[cam_id] = frame_with_boxes\n",
    "            latest_frames[cam_id] = frame_with_boxes\n",
    "        else:\n",
    "            # Si no es frame de inferencia, mostramos último frame con detecciones\n",
    "            if last_detected_frames[cam_id] is not None:\n",
    "                latest_frames[cam_id] = last_detected_frames[cam_id]\n",
    "            else:\n",
    "                latest_frames[cam_id] = frame\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    html = \"\"\"\n",
    "    <html>\n",
    "    <head><title>Vista Múltiple de Cámaras</title></head>\n",
    "    <body>\n",
    "        <h1>Vista en vivo</h1>\n",
    "        {% for cam_id in camera_ids %}\n",
    "            <div>\n",
    "                <h2>{{ cam_id }}</h2>\n",
    "                <img src=\"/video_feed/{{ cam_id }}\" width=\"640\" height=\"360\"/>\n",
    "            </div>\n",
    "        {% endfor %}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return render_template_string(html, camera_ids=camera_urls.keys())\n",
    "\n",
    "@app.route('/video_feed/<cam_id>')\n",
    "def video_feed(cam_id):\n",
    "    def generate():\n",
    "        while True:\n",
    "            frame = latest_frames.get(cam_id)\n",
    "            if frame is None:\n",
    "                time.sleep(0.1)\n",
    "                continue\n",
    "            ret, jpeg = cv2.imencode('.jpg', frame)\n",
    "            if not ret:\n",
    "                continue\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + jpeg.tobytes() + b'\\r\\n')\n",
    "            #time.sleep(0.05)\n",
    "    return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "for cam_id, url in camera_urls.items():\n",
    "    t = Thread(target=camera_reader, args=(cam_id, url), daemon=True)\n",
    "    t.start()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, threaded=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
